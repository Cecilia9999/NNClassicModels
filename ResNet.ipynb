{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5AIV+zjWtdDLJIKQVza3V"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8QcKCueH0fak","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593764732316,"user_tz":-540,"elapsed":841,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTyjksCk0u2l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593764734437,"user_tz":-540,"elapsed":911,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","num_epochs = 80\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# image preprocessing modules\n","# data augmentation\n","transform = transforms.Compose([transforms.Pad(4),\n","                                transforms.RandomHorizontalFlip(), # default p=0.5\n","                                transforms.RandomCrop(32),\n","                                transforms.ToTensor()\n","                                ])"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrdZPE920zWt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593759503876,"user_tz":-540,"elapsed":2424,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}},"outputId":"fa2f685a-ad22-40f2-8193-e7bf273b961d"},"source":["# CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n","                                             train=True,\n","                                             transform=transform,\n","                                             download=True\n","                                             )\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n","                                            train=False,\n","                                            transform=transforms.ToTensor()\n","                                            ) \n","             \n","# data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=2\n","                                           )\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          num_workers=2\n","                                          )\n","\n","# 3 x 3 Convolution\n","def conv3x3(in_channels, out_channels, stride=1):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n","                     stride=stride, padding=1, bias=False)\n","    \n","# Residual block\n","class ResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResBlock, self).__init__()\n","        self.conv1 = conv3x3(in_channels, out_channels, stride)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(out_channels, out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","    \n","    def forward(self, x):\n","        residual = x\n","        out1 = self.conv1(x)\n","        out1 = self.bn1(out1)\n","        out1 = self.relu(out1)\n","        out2 = self.conv2(out1)\n","        out2 = self.bn2(out2)\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out = out2 + residual\n","        out = self.relu(out)\n","        return out\n","\n","# Residual NN\n","class ResNN(nn.Module):\n","    def __init__(self, block, layers, num_classes=10):\n","        super(ResNN, self).__init__()\n","        self.in_channels = 16           # num_kernels\n","        self.conv = conv3x3(3, 16)      # RGB --> num_kernels\n","        self.bn = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self.make_layer(block, 16, layers[0])\n","        self.layer2 = self.make_layer(block, 32, layers[1], 2) # layers: num of repeated blocks\n","        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n","        self.avg_pool = nn.AvgPool2d(8)\n","        self.fc = nn.Linear(64, num_classes)\n","\n","    # construct more layers composed by blocks\n","    def make_layer(self, block, out_channels, blocks, stride=1):\n","        downsample = None\n","        if (stride != 1) or (self.in_channels != out_channels):\n","            downsample = nn.Sequential(conv3x3(self.in_channels, out_channels, stride=stride),\n","                                       nn.BatchNorm2d(out_channels)\n","                                       )\n","        \n","        layers = []\n","\n","        # here, block is from 'ResBlock' instance\n","        layers.append(block(self.in_channels, out_channels, stride, downsample))\n","        self.in_channels = out_channels\n","        for i in range(1, blocks):  # blocks: num of repeated resblock\n","            layers.append(block(out_channels, out_channels))\n","        \n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv(x)\n","        out = self.bn(out)\n","        out = self.relu(out)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.avg_pool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MpNcywiMIYrm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593764738858,"user_tz":-540,"elapsed":660,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["model = ResNN(ResBlock, [2, 2, 2, 2]).to(device)\n","\n","# loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# update learning rate\n","def update_lr(optimizer, lr):\n","    for para in optimizer.param_groups:\n","        para['lr'] = lr \n","\n"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DboUO7xRNWqx","colab_type":"text"},"source":["注：使用衰减learning rate，刚开始epoch用大一点lr快速下降，后期的epoch中用小lr慢慢搜索"]},{"cell_type":"code","metadata":{"id":"qMHw_TEENUz6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1593764792697,"user_tz":-540,"elapsed":49646,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}},"outputId":"d4fb585b-72f4-4410-a74b-7f5b3ca0b7dd"},"source":["# train model\n","total_step = len(train_loader)\n","print('Each epoch has {} iterations'.format(total_step))\n","cur_lr = learning_rate\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # forward\n","        output = model(images)\n","        loss = criterion(output, labels)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","        # decay learning rate\n","        if (epoch+1) % 20 == 0:\n","            cur_lr /= 3\n","            update_lr(optimizer, cur_lr)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["500\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-33e14a0c8cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"eDQYgxXVPLLe","colab_type":"code","colab":{}},"source":["# test model\n","model.eval()            \n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predict = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predict == labels).sum().item()\n","\n","    print('Accuracy of model is {}'.format(100*correct/total))\n","\n","# save model\n","# torch.save(model.state_dict(), 'resnet.pkl')"],"execution_count":null,"outputs":[]}]}