{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyONx2h8WB77O+MNncO/dofP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vYDw7Ym2_YUw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593863110497,"user_tz":-540,"elapsed":639,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","%matplotlib inline"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVsu_XppWijK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593863113771,"user_tz":-540,"elapsed":2506,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}},"outputId":"04c8b8eb-9f92-4952-ad8e-94826264357c"},"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# Image preprocessing modules\n","transform = transforms.Compose([\n","    transforms.Pad(4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor()])\n","\n","# CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n","                                             train=True, \n","                                             transform=transform,\n","                                             download=True)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n","                                            train=False, \n","                                            transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=2\n","                                           )\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          num_workers=2\n","                                          )\n"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JfNIqwoj_xw9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593863118765,"user_tz":-540,"elapsed":659,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["# VGG-16\n","class VGG16(nn.Module):\n","    def __init__(self, in_chan, num_classes, use_BN=True):\n","        super(VGG16, self).__init__()\n","        self._model_name = 'VGG16'\n","        \n","        self.feature = nn.Sequential(\n","                           self.make_layer(2, use_BN, in_chan, 64, 3, 1, 1),\n","                           self.make_layer(2, use_BN, 64, 128, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 128, 256, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 256, 512, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 512, 512, 3, 1, 1)\n","                           )\n","        '''\n","        self.layer1 = self.make_layer(2, use_BN, in_chan, 64, 3, 1, 1)\n","        self.layer2 = self.make_layer(2, use_BN, 64, 128, 3, 1, 1)\n","        self.layer3 = self.make_layer(3, use_BN, 128, 256, 3, 1, 1)\n","        self.layer4 = self.make_layer(3, use_BN, 256, 512, 3, 1, 1)\n","        self.layer5 = self.make_layer(3, use_BN, 512, 512, 3, 1, 1)\n","        self.avg_pool = nn.AvgPool2d(1, stride=1)\n","        '''\n","        self.classifier = nn.Sequential(\n","                            nn.Linear(7*7*512, 4096),\n","                            nn.ReLU(inplace=True),\n","                            nn.Dropout(),\n","\n","                            nn.Linear(4096, 4096),\n","                            nn.ReLU(inplace=True),\n","                            nn.Dropout(),\n","\n","                            nn.Linear(4096, num_classes)                            \n","                          )\n","\n","    def make_layer(self, repeat, bn, in_chan, out_chan, size, s=1, p=0):\n","        layer = []\n","        if bn:\n","            layer += [nn.Conv2d(in_chan, out_chan, kernel_size=size, \n","                                stride=s, padding=p), \n","                      nn.BatchNorm2d(out_chan), \n","                      nn.ReLU(inplace=True)]\n","        else:\n","            layer += [nn.Conv2d(in_chan, out_chan, kernel_size=size, \n","                                stride=s, padding=p),\n","                      nn.ReLU(inplace=True)]\n","        layer.append(nn.MaxPool2d(2, 2))\n","        return nn.Sequential(*layer)\n","\n","    def forward(self, x):\n","        out = self.feature(x)\n","        #out = self.avg_pool(out)\n","        print(out.size(0))\n","        out = out.view(out.size(0), -1)\n","        \n","        out = self.classifier(out)\n","        return out"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jHC8SLaWNus","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593863120878,"user_tz":-540,"elapsed":689,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["# VGG-16 for CIFAR-10\n","class VGG16_CIFAR(nn.Module):\n","    def __init__(self, in_chan, num_classes, use_BN=True):\n","        super(VGG16_CIFAR, self).__init__()\n","        self._model_name = 'VGG16_CIFAR'\n","        \n","        self.feature = nn.Sequential(\n","                           self.make_layer(2, use_BN, in_chan, 64, 3, 1, 1),\n","                           self.make_layer(2, use_BN, 64, 128, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 128, 256, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 256, 512, 3, 1, 1),\n","                           self.make_layer(3, use_BN, 512, 512, 3, 1, 1)\n","                           )\n","        self.classifier = nn.Sequential(\n","                            nn.Linear(512, 4096),\n","                            nn.ReLU(inplace=True),\n","                            nn.Dropout(),\n","                            nn.Linear(4096, num_classes)                            \n","                          )\n","\n","    def make_layer(self, repeat, bn, in_chan, out_chan, size, s=1, p=0):\n","        layer = []\n","        if bn:\n","            layer += [nn.Conv2d(in_chan, out_chan, kernel_size=size, \n","                                stride=s, padding=p), \n","                      nn.BatchNorm2d(out_chan), \n","                      nn.ReLU(inplace=True)]\n","        else:\n","            layer += [nn.Conv2d(in_chan, out_chan, kernel_size=size, \n","                                stride=s, padding=p),\n","                      nn.ReLU(inplace=True)]\n","        layer.append(nn.MaxPool2d(2, 2))\n","        return nn.Sequential(*layer)\n","\n","    def forward(self, x):\n","        out = self.feature(x)\n","        out = out.view(out.size(0), -1)\n","        \n","        out = self.classifier(out)\n","        return out"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSyebkm2QoSm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593863123782,"user_tz":-540,"elapsed":722,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}}},"source":["model = VGG16_CIFAR(3, 10).to(device)"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpdWOxvEOlPo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1593866327281,"user_tz":-540,"elapsed":3200274,"user":{"displayName":"Cecilia SS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZdujNRISiRFR_Nh34nbB8-fEtGSvGXr2rEpf5=s64","userId":"04154856476552279883"}},"outputId":"48be2e3c-7100-400c-e21c-e884f849a08d"},"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# For updating learning rate\n","def update_lr(optimizer, lr):    \n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","# Train the model\n","total_step = len(train_loader)\n","curr_lr = learning_rate\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","    # Decay learning rate\n","    if (epoch+1) % 20 == 0:\n","        curr_lr /= 3\n","        update_lr(optimizer, curr_lr)\n","\n","# Test the model\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","# torch.save(model.state_dict(), 'vgg16.pkl')"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Epoch [1/5], Step [100/500] Loss: 1.7916\n","Epoch [1/5], Step [200/500] Loss: 1.5203\n","Epoch [1/5], Step [300/500] Loss: 1.2034\n","Epoch [1/5], Step [400/500] Loss: 1.4512\n","Epoch [1/5], Step [500/500] Loss: 1.1757\n","Epoch [2/5], Step [100/500] Loss: 0.9788\n","Epoch [2/5], Step [200/500] Loss: 1.0694\n","Epoch [2/5], Step [300/500] Loss: 0.9198\n","Epoch [2/5], Step [400/500] Loss: 0.9541\n","Epoch [2/5], Step [500/500] Loss: 0.7983\n","Epoch [3/5], Step [100/500] Loss: 0.8585\n","Epoch [3/5], Step [200/500] Loss: 0.8455\n","Epoch [3/5], Step [300/500] Loss: 0.6314\n","Epoch [3/5], Step [400/500] Loss: 0.7121\n","Epoch [3/5], Step [500/500] Loss: 0.4663\n","Epoch [4/5], Step [100/500] Loss: 0.8501\n","Epoch [4/5], Step [200/500] Loss: 0.7719\n","Epoch [4/5], Step [300/500] Loss: 0.7529\n","Epoch [4/5], Step [400/500] Loss: 0.7119\n","Epoch [4/5], Step [500/500] Loss: 0.7789\n","Epoch [5/5], Step [100/500] Loss: 0.5653\n","Epoch [5/5], Step [200/500] Loss: 0.6259\n","Epoch [5/5], Step [300/500] Loss: 0.5535\n","Epoch [5/5], Step [400/500] Loss: 0.6044\n","Epoch [5/5], Step [500/500] Loss: 0.6286\n","Accuracy of the model on the test images: 78.77 %\n"],"name":"stdout"}]}]}